resources:
  jobs:
    ingest_and_dedup_openaq_data:
      name: Run OpenAQ ingestion pipeline and dedup data

      description: Run OpenAQ ingestion pipeline and deduplicate data
      max_concurrent_runs: 1

      tasks:        
        - task_key: run_measurements_etl_pipeline
          pipeline_task:
            pipeline_id: ${resources.pipelines.ingest-openaq-measurements.id}
            full_refresh: false
        - task_key: dedup_measurements
          environment_key: default
          max_retries: 1
          min_retry_interval_millis: 60000
          run_if: ALL_SUCCESS
          spark_python_task:
            python_file: ../src/dedup_openaq_measurements.py
          depends_on:
            - task_key: run_measurements_etl_pipeline

      environments:
      - environment_key: default
        spec:
          dependencies:
            - openaq
          environment_version: "4"